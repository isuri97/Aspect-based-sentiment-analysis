{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/isuri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Other\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspect</th>\n",
       "      <th>aspect_category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place</td>\n",
       "      <td>RESTAURANT#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>\\nJudging from previous posts this used to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>\\nWe, there were four of us, arrived at noon -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>\\nThey never brought us complimentary noodles,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>negative</td>\n",
       "      <td>\\nThe food was lousy - too sweet or too salty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>portions</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>negative</td>\n",
       "      <td>\\nThe food was lousy - too sweet or too salty ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     aspect     aspect_category sentiment  \\\n",
       "0     place  RESTAURANT#GENERAL  negative   \n",
       "1     staff     SERVICE#GENERAL  negative   \n",
       "2       nan     SERVICE#GENERAL  negative   \n",
       "3      food        FOOD#QUALITY  negative   \n",
       "4  portions  FOOD#STYLE_OPTIONS  negative   \n",
       "\n",
       "                                              review  \n",
       "0  \\nJudging from previous posts this used to be ...  \n",
       "1  \\nWe, there were four of us, arrived at noon -...  \n",
       "2  \\nThey never brought us complimentary noodles,...  \n",
       "3  \\nThe food was lousy - too sweet or too salty ...  \n",
       "4  \\nThe food was lousy - too sweet or too salty ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "reviews_train = pd.read_csv(\"hotel.csv\").astype(str)\n",
    "\n",
    "#show first 5 records\n",
    "reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_category\n",
      "FOOD#QUALITY                849\n",
      "SERVICE#GENERAL             449\n",
      "RESTAURANT#GENERAL          422\n",
      "AMBIENCE#GENERAL            255\n",
      "FOOD#STYLE_OPTIONS          137\n",
      "RESTAURANT#MISCELLANEOUS     98\n",
      "FOOD#PRICES                  90\n",
      "RESTAURANT#PRICES            80\n",
      "DRINKS#QUALITY               47\n",
      "DRINKS#STYLE_OPTIONS         32\n",
      "LOCATION#GENERAL             28\n",
      "DRINKS#PRICES                20\n",
      "dtype: int64\n",
      "number of categories 12\n"
     ]
    }
   ],
   "source": [
    "# reviews_train.columns\n",
    "print(reviews_train.groupby('aspect_category').size().sort_values(ascending=False))\n",
    "\n",
    "#how many categories\n",
    "print(\"number of categories\",reviews_train.aspect_category.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a word embedding of reviews data\n",
    "vocab_size = 6000 # We set a maximum size for the vocabulary\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(reviews_train.review)\n",
    "reviews_tokenized = pd.DataFrame(tokenizer.texts_to_matrix(reviews_train.review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "absa_model = Sequential()\n",
    "absa_model.add(Dense(512, input_shape=(6000,), activation='relu'))\n",
    "absa_model.add((Dense(256, activation='relu')))\n",
    "absa_model.add((Dense(128, activation='relu')))\n",
    "absa_model.add(Dense(12, activation='softmax'))\n",
    "#compile model\n",
    "absa_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_category = label_encoder.fit_transform(reviews_train.aspect_category)\n",
    "encoded_y = to_categorical(integer_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2507/2507 [==============================] - 2s 866us/step - loss: 1.7995 - accuracy: 0.4360\n",
      "Epoch 2/100\n",
      "2507/2507 [==============================] - 2s 838us/step - loss: 1.1558 - accuracy: 0.6191\n",
      "Epoch 3/100\n",
      "2507/2507 [==============================] - 2s 839us/step - loss: 0.8637 - accuracy: 0.6737\n",
      "Epoch 4/100\n",
      "2507/2507 [==============================] - 2s 825us/step - loss: 0.6886 - accuracy: 0.6964\n",
      "Epoch 5/100\n",
      "2507/2507 [==============================] - 2s 825us/step - loss: 0.5957 - accuracy: 0.7140\n",
      "Epoch 6/100\n",
      "2507/2507 [==============================] - 2s 847us/step - loss: 0.5396 - accuracy: 0.7248\n",
      "Epoch 7/100\n",
      "2507/2507 [==============================] - 2s 833us/step - loss: 0.5133 - accuracy: 0.7204\n",
      "Epoch 8/100\n",
      "2507/2507 [==============================] - 2s 833us/step - loss: 0.4770 - accuracy: 0.7347\n",
      "Epoch 9/100\n",
      "2507/2507 [==============================] - 2s 845us/step - loss: 0.4570 - accuracy: 0.7371\n",
      "Epoch 10/100\n",
      "2507/2507 [==============================] - 2s 840us/step - loss: 0.4464 - accuracy: 0.7331\n",
      "Epoch 11/100\n",
      "2507/2507 [==============================] - 2s 837us/step - loss: 0.4396 - accuracy: 0.7316\n",
      "Epoch 12/100\n",
      "2507/2507 [==============================] - 2s 837us/step - loss: 0.4381 - accuracy: 0.7431\n",
      "Epoch 13/100\n",
      "2507/2507 [==============================] - 2s 839us/step - loss: 0.4246 - accuracy: 0.7343\n",
      "Epoch 14/100\n",
      "2507/2507 [==============================] - 2s 840us/step - loss: 0.4188 - accuracy: 0.7331\n",
      "Epoch 15/100\n",
      "2507/2507 [==============================] - 2s 837us/step - loss: 0.4119 - accuracy: 0.7459\n",
      "Epoch 16/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.4143 - accuracy: 0.7292\n",
      "Epoch 17/100\n",
      "2507/2507 [==============================] - 2s 826us/step - loss: 0.4066 - accuracy: 0.7415\n",
      "Epoch 18/100\n",
      "2507/2507 [==============================] - 2s 849us/step - loss: 0.4080 - accuracy: 0.7407\n",
      "Epoch 19/100\n",
      "2507/2507 [==============================] - 2s 843us/step - loss: 0.4053 - accuracy: 0.7363\n",
      "Epoch 20/100\n",
      "2507/2507 [==============================] - 2s 852us/step - loss: 0.4006 - accuracy: 0.7467\n",
      "Epoch 21/100\n",
      "2507/2507 [==============================] - 2s 836us/step - loss: 0.4004 - accuracy: 0.7403\n",
      "Epoch 22/100\n",
      "2507/2507 [==============================] - 2s 864us/step - loss: 0.3966 - accuracy: 0.7551\n",
      "Epoch 23/100\n",
      "2507/2507 [==============================] - 2s 855us/step - loss: 0.3953 - accuracy: 0.7439\n",
      "Epoch 24/100\n",
      "2507/2507 [==============================] - 2s 839us/step - loss: 0.3951 - accuracy: 0.7439\n",
      "Epoch 25/100\n",
      "2507/2507 [==============================] - 2s 844us/step - loss: 0.3916 - accuracy: 0.7519\n",
      "Epoch 26/100\n",
      "2507/2507 [==============================] - 2s 847us/step - loss: 0.3891 - accuracy: 0.7427\n",
      "Epoch 27/100\n",
      "2507/2507 [==============================] - 2s 849us/step - loss: 0.3878 - accuracy: 0.7459\n",
      "Epoch 28/100\n",
      "2507/2507 [==============================] - 2s 847us/step - loss: 0.3870 - accuracy: 0.7511\n",
      "Epoch 29/100\n",
      "2507/2507 [==============================] - 2s 851us/step - loss: 0.3867 - accuracy: 0.7539\n",
      "Epoch 30/100\n",
      "2507/2507 [==============================] - 2s 839us/step - loss: 0.3857 - accuracy: 0.7483\n",
      "Epoch 31/100\n",
      "2507/2507 [==============================] - 2s 850us/step - loss: 0.3847 - accuracy: 0.7559\n",
      "Epoch 32/100\n",
      "2507/2507 [==============================] - 2s 840us/step - loss: 0.3865 - accuracy: 0.7539\n",
      "Epoch 33/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.3854 - accuracy: 0.7611\n",
      "Epoch 34/100\n",
      "2507/2507 [==============================] - 2s 871us/step - loss: 0.3866 - accuracy: 0.7435\n",
      "Epoch 35/100\n",
      "2507/2507 [==============================] - 2s 838us/step - loss: 0.3832 - accuracy: 0.7523\n",
      "Epoch 36/100\n",
      "2507/2507 [==============================] - 2s 867us/step - loss: 0.3844 - accuracy: 0.7527\n",
      "Epoch 37/100\n",
      "2507/2507 [==============================] - 2s 873us/step - loss: 0.3919 - accuracy: 0.7467\n",
      "Epoch 38/100\n",
      "2507/2507 [==============================] - 2s 838us/step - loss: 0.3899 - accuracy: 0.7467\n",
      "Epoch 39/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.3871 - accuracy: 0.7431\n",
      "Epoch 40/100\n",
      "2507/2507 [==============================] - 2s 861us/step - loss: 0.3836 - accuracy: 0.7487\n",
      "Epoch 41/100\n",
      "2507/2507 [==============================] - 2s 860us/step - loss: 0.3783 - accuracy: 0.7599\n",
      "Epoch 42/100\n",
      "2507/2507 [==============================] - 2s 835us/step - loss: 0.3769 - accuracy: 0.7539\n",
      "Epoch 43/100\n",
      "2507/2507 [==============================] - 2s 899us/step - loss: 0.3792 - accuracy: 0.7535\n",
      "Epoch 44/100\n",
      "2507/2507 [==============================] - 2s 877us/step - loss: 0.3767 - accuracy: 0.7559\n",
      "Epoch 45/100\n",
      "2507/2507 [==============================] - 2s 882us/step - loss: 0.3804 - accuracy: 0.7563\n",
      "Epoch 46/100\n",
      "2507/2507 [==============================] - 2s 873us/step - loss: 0.3801 - accuracy: 0.7475\n",
      "Epoch 47/100\n",
      "2507/2507 [==============================] - 2s 880us/step - loss: 0.3814 - accuracy: 0.7487\n",
      "Epoch 48/100\n",
      "2507/2507 [==============================] - 2s 880us/step - loss: 0.3792 - accuracy: 0.7435\n",
      "Epoch 49/100\n",
      "2507/2507 [==============================] - 2s 865us/step - loss: 0.3762 - accuracy: 0.7511\n",
      "Epoch 50/100\n",
      "2507/2507 [==============================] - 2s 873us/step - loss: 0.3782 - accuracy: 0.7495\n",
      "Epoch 51/100\n",
      "2507/2507 [==============================] - 2s 869us/step - loss: 0.3773 - accuracy: 0.7571\n",
      "Epoch 52/100\n",
      "2507/2507 [==============================] - 2s 876us/step - loss: 0.3783 - accuracy: 0.7463\n",
      "Epoch 53/100\n",
      "2507/2507 [==============================] - 2s 867us/step - loss: 0.3780 - accuracy: 0.7499\n",
      "Epoch 54/100\n",
      "2507/2507 [==============================] - 2s 878us/step - loss: 0.3747 - accuracy: 0.7523\n",
      "Epoch 55/100\n",
      "2507/2507 [==============================] - 2s 879us/step - loss: 0.3757 - accuracy: 0.7563\n",
      "Epoch 56/100\n",
      "2507/2507 [==============================] - 2s 878us/step - loss: 0.3719 - accuracy: 0.7483\n",
      "Epoch 57/100\n",
      "2507/2507 [==============================] - 2s 868us/step - loss: 0.3766 - accuracy: 0.7527\n",
      "Epoch 58/100\n",
      "2507/2507 [==============================] - 2s 870us/step - loss: 0.3753 - accuracy: 0.7615\n",
      "Epoch 59/100\n",
      "2507/2507 [==============================] - 2s 890us/step - loss: 0.3747 - accuracy: 0.7487\n",
      "Epoch 60/100\n",
      "2507/2507 [==============================] - 2s 869us/step - loss: 0.3748 - accuracy: 0.7539\n",
      "Epoch 61/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.3763 - accuracy: 0.7531\n",
      "Epoch 62/100\n",
      "2507/2507 [==============================] - 2s 834us/step - loss: 0.3763 - accuracy: 0.7507\n",
      "Epoch 63/100\n",
      "2507/2507 [==============================] - 2s 848us/step - loss: 0.3739 - accuracy: 0.7543\n",
      "Epoch 64/100\n",
      "2507/2507 [==============================] - 2s 842us/step - loss: 0.3745 - accuracy: 0.7567\n",
      "Epoch 65/100\n",
      "2507/2507 [==============================] - 2s 816us/step - loss: 0.3753 - accuracy: 0.7643\n",
      "Epoch 66/100\n",
      "2507/2507 [==============================] - 2s 855us/step - loss: 0.3800 - accuracy: 0.7523\n",
      "Epoch 67/100\n",
      "2507/2507 [==============================] - 2s 841us/step - loss: 0.3746 - accuracy: 0.7567\n",
      "Epoch 68/100\n",
      "2507/2507 [==============================] - 2s 833us/step - loss: 0.3766 - accuracy: 0.7563\n",
      "Epoch 69/100\n",
      "2507/2507 [==============================] - 2s 828us/step - loss: 0.3745 - accuracy: 0.7575\n",
      "Epoch 70/100\n",
      "2507/2507 [==============================] - 2s 833us/step - loss: 0.3717 - accuracy: 0.7567\n",
      "Epoch 71/100\n",
      "2507/2507 [==============================] - 2s 855us/step - loss: 0.3717 - accuracy: 0.7547\n",
      "Epoch 72/100\n",
      "2507/2507 [==============================] - 2s 852us/step - loss: 0.3708 - accuracy: 0.7615\n",
      "Epoch 73/100\n",
      "2507/2507 [==============================] - 2s 838us/step - loss: 0.3722 - accuracy: 0.7463\n",
      "Epoch 74/100\n",
      "2507/2507 [==============================] - 2s 817us/step - loss: 0.3842 - accuracy: 0.7567\n",
      "Epoch 75/100\n",
      "2507/2507 [==============================] - 2s 842us/step - loss: 0.3799 - accuracy: 0.7451\n",
      "Epoch 76/100\n",
      "2507/2507 [==============================] - 2s 861us/step - loss: 0.3887 - accuracy: 0.7607\n",
      "Epoch 77/100\n",
      "2507/2507 [==============================] - 2s 853us/step - loss: 0.3906 - accuracy: 0.7467\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 2s 853us/step - loss: 0.3802 - accuracy: 0.7559\n",
      "Epoch 79/100\n",
      "2507/2507 [==============================] - 2s 822us/step - loss: 0.3703 - accuracy: 0.7599\n",
      "Epoch 80/100\n",
      "2507/2507 [==============================] - 2s 833us/step - loss: 0.3703 - accuracy: 0.7587\n",
      "Epoch 81/100\n",
      "2507/2507 [==============================] - 2s 827us/step - loss: 0.3701 - accuracy: 0.7507\n",
      "Epoch 82/100\n",
      "2507/2507 [==============================] - 2s 835us/step - loss: 0.3718 - accuracy: 0.7451\n",
      "Epoch 83/100\n",
      "2507/2507 [==============================] - 2s 826us/step - loss: 0.3693 - accuracy: 0.7583\n",
      "Epoch 84/100\n",
      "2507/2507 [==============================] - 2s 835us/step - loss: 0.3683 - accuracy: 0.7527\n",
      "Epoch 85/100\n",
      "2507/2507 [==============================] - 2s 830us/step - loss: 0.3690 - accuracy: 0.7535\n",
      "Epoch 86/100\n",
      "2507/2507 [==============================] - 2s 824us/step - loss: 0.3669 - accuracy: 0.7675\n",
      "Epoch 87/100\n",
      "2507/2507 [==============================] - 2s 835us/step - loss: 0.3674 - accuracy: 0.7615\n",
      "Epoch 88/100\n",
      "2507/2507 [==============================] - 2s 813us/step - loss: 0.3653 - accuracy: 0.7587\n",
      "Epoch 89/100\n",
      "2507/2507 [==============================] - 2s 791us/step - loss: 0.3709 - accuracy: 0.7539\n",
      "Epoch 90/100\n",
      "2507/2507 [==============================] - 2s 812us/step - loss: 0.3683 - accuracy: 0.7559\n",
      "Epoch 91/100\n",
      "2507/2507 [==============================] - 2s 803us/step - loss: 0.3671 - accuracy: 0.7547\n",
      "Epoch 92/100\n",
      "2507/2507 [==============================] - 2s 810us/step - loss: 0.3655 - accuracy: 0.7686\n",
      "Epoch 93/100\n",
      "2507/2507 [==============================] - 2s 824us/step - loss: 0.3670 - accuracy: 0.7575\n",
      "Epoch 94/100\n",
      "2507/2507 [==============================] - 2s 870us/step - loss: 0.3707 - accuracy: 0.7587\n",
      "Epoch 95/100\n",
      "2507/2507 [==============================] - 2s 886us/step - loss: 0.3690 - accuracy: 0.7511\n",
      "Epoch 96/100\n",
      "2507/2507 [==============================] - 2s 882us/step - loss: 0.3667 - accuracy: 0.7567\n",
      "Epoch 97/100\n",
      "2507/2507 [==============================] - 2s 882us/step - loss: 0.3700 - accuracy: 0.7451\n",
      "Epoch 98/100\n",
      "2507/2507 [==============================] - 2s 881us/step - loss: 0.3663 - accuracy: 0.7599\n",
      "Epoch 99/100\n",
      "2507/2507 [==============================] - 2s 884us/step - loss: 0.3661 - accuracy: 0.7663\n",
      "Epoch 100/100\n",
      "2507/2507 [==============================] - 2s 875us/step - loss: 0.3658 - accuracy: 0.7627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f21bc3ef358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit aspect classifier\n",
    "absa_model.fit(reviews_tokenized, encoded_y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = [\n",
    "    \"Good, fast service.\",\n",
    "    \"The hostess was very pleasant.\",\n",
    "    \"The bread was stale, the salad was overpriced and empty.\",\n",
    "    \"The food we ordered was excellent, although I wouldn't say the margaritas were anything to write home about.\",\n",
    "    \"This place has totally weird decor, stairs going up with mirrored walls - I am surprised how no one yet broke their head or fall off the stairs\"\n",
    "]\n",
    "\n",
    "# Aspect preprocessing\n",
    "# test_reviews = [review.lower() for review in test_reviews]\n",
    "test_aspect_terms = []\n",
    "for review in nlp.pipe(test_reviews):\n",
    "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "    test_aspect_terms.append(' '.join(chunks))\n",
    "test_aspect_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_aspect_terms))\n",
    "                             \n",
    "\n",
    "# Models output\n",
    "test_aspect_categories = label_encoder.inverse_transform(absa_model.predict_classes(test_aspect_terms))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Good, fast service. is opinion about SERVICE#GENERAL\n",
      "Review: The hostess was very pleasant. is opinion about SERVICE#GENERAL\n",
      "Review: The bread was stale, the salad was overpriced and empty. is opinion about FOOD#STYLE_OPTIONS\n",
      "Review: The food we ordered was excellent, although I wouldn't say the margaritas were anything to write home about. is opinion about FOOD#QUALITY\n",
      "Review: This place has totally weird decor, stairs going up with mirrored walls - I am surprised how no one yet broke their head or fall off the stairs is opinion about AMBIENCE#GENERAL\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(test_reviews,test_aspect_categories):\n",
    "    print(\"Review:\"+\" \"+str(i)+\" \"+\"is opinion about\"+ \" \" +str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture\n",
    "sentiment_model = Sequential()\n",
    "sentiment_model.add(Dense(512, input_shape=(6000,), activation='relu'))\n",
    "sentiment_model.add((Dense(256, activation='relu')))\n",
    "sentiment_model.add((Dense(128, activation='relu')))\n",
    "sentiment_model.add(Dense(3, activation='softmax'))\n",
    "#compile model\n",
    "sentiment_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "#encode the label variable\n",
    "label_encoder = LabelEncoder()\n",
    "integer_sentiment1 = label_encoder.fit_transform(reviews_train.sentiment)\n",
    "encoded_y1 = to_categorical(integer_sentiment1)\n",
    "dummy_new = pd.get_dummies(integer_sentiment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2507/2507 [==============================] - 2s 868us/step - loss: 0.6334 - accuracy: 0.7419\n",
      "Epoch 2/100\n",
      "2507/2507 [==============================] - 2s 825us/step - loss: 0.3415 - accuracy: 0.8688\n",
      "Epoch 3/100\n",
      "2507/2507 [==============================] - 2s 856us/step - loss: 0.2160 - accuracy: 0.8975\n",
      "Epoch 4/100\n",
      "2507/2507 [==============================] - 2s 855us/step - loss: 0.1575 - accuracy: 0.9194\n",
      "Epoch 5/100\n",
      "2507/2507 [==============================] - 2s 836us/step - loss: 0.1246 - accuracy: 0.9282\n",
      "Epoch 6/100\n",
      "2507/2507 [==============================] - 2s 834us/step - loss: 0.1153 - accuracy: 0.9238\n",
      "Epoch 7/100\n",
      "2507/2507 [==============================] - 2s 860us/step - loss: 0.1069 - accuracy: 0.9230\n",
      "Epoch 8/100\n",
      "2507/2507 [==============================] - 2s 839us/step - loss: 0.1031 - accuracy: 0.9350\n",
      "Epoch 9/100\n",
      "2507/2507 [==============================] - 2s 827us/step - loss: 0.1025 - accuracy: 0.9314\n",
      "Epoch 10/100\n",
      "2507/2507 [==============================] - 2s 851us/step - loss: 0.1006 - accuracy: 0.9366\n",
      "Epoch 11/100\n",
      "2507/2507 [==============================] - 2s 856us/step - loss: 0.0993 - accuracy: 0.9306\n",
      "Epoch 12/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.0995 - accuracy: 0.9318\n",
      "Epoch 13/100\n",
      "2507/2507 [==============================] - 2s 830us/step - loss: 0.0967 - accuracy: 0.9394\n",
      "Epoch 14/100\n",
      "2507/2507 [==============================] - 2s 852us/step - loss: 0.0998 - accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "2507/2507 [==============================] - 2s 849us/step - loss: 0.0981 - accuracy: 0.9334\n",
      "Epoch 16/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.1004 - accuracy: 0.9382\n",
      "Epoch 17/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.0984 - accuracy: 0.9374\n",
      "Epoch 18/100\n",
      "2507/2507 [==============================] - 2s 857us/step - loss: 0.0990 - accuracy: 0.9330\n",
      "Epoch 19/100\n",
      "2507/2507 [==============================] - 2s 864us/step - loss: 0.0970 - accuracy: 0.9334\n",
      "Epoch 20/100\n",
      "2507/2507 [==============================] - 2s 824us/step - loss: 0.0969 - accuracy: 0.9298\n",
      "Epoch 21/100\n",
      "2507/2507 [==============================] - 2s 833us/step - loss: 0.0966 - accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "2507/2507 [==============================] - 2s 826us/step - loss: 0.0959 - accuracy: 0.9354\n",
      "Epoch 23/100\n",
      "2507/2507 [==============================] - 2s 839us/step - loss: 0.0964 - accuracy: 0.9342\n",
      "Epoch 24/100\n",
      "2507/2507 [==============================] - 2s 832us/step - loss: 0.0954 - accuracy: 0.9358\n",
      "Epoch 25/100\n",
      "2507/2507 [==============================] - 2s 853us/step - loss: 0.0965 - accuracy: 0.9382\n",
      "Epoch 26/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.0973 - accuracy: 0.9398\n",
      "Epoch 27/100\n",
      "2507/2507 [==============================] - 2s 842us/step - loss: 0.1037 - accuracy: 0.9326\n",
      "Epoch 28/100\n",
      "2507/2507 [==============================] - 2s 842us/step - loss: 0.1035 - accuracy: 0.9366\n",
      "Epoch 29/100\n",
      "2507/2507 [==============================] - 2s 852us/step - loss: 0.1359 - accuracy: 0.9262\n",
      "Epoch 30/100\n",
      "2507/2507 [==============================] - 2s 845us/step - loss: 0.1372 - accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "2507/2507 [==============================] - 3s 1ms/step - loss: 0.1048 - accuracy: 0.9342\n",
      "Epoch 32/100\n",
      "2507/2507 [==============================] - 2s 848us/step - loss: 0.0991 - accuracy: 0.9294\n",
      "Epoch 33/100\n",
      "2507/2507 [==============================] - 2s 843us/step - loss: 0.0987 - accuracy: 0.9366\n",
      "Epoch 34/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.0951 - accuracy: 0.9406\n",
      "Epoch 35/100\n",
      "2507/2507 [==============================] - 2s 862us/step - loss: 0.0958 - accuracy: 0.9394\n",
      "Epoch 36/100\n",
      "2507/2507 [==============================] - 2s 848us/step - loss: 0.1007 - accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "2507/2507 [==============================] - 2s 856us/step - loss: 0.0971 - accuracy: 0.9394\n",
      "Epoch 38/100\n",
      "2507/2507 [==============================] - 2s 852us/step - loss: 0.0965 - accuracy: 0.9374\n",
      "Epoch 39/100\n",
      "2507/2507 [==============================] - 2s 863us/step - loss: 0.0955 - accuracy: 0.9374\n",
      "Epoch 40/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.0964 - accuracy: 0.9366\n",
      "Epoch 41/100\n",
      "2507/2507 [==============================] - 2s 850us/step - loss: 0.0955 - accuracy: 0.9410\n",
      "Epoch 42/100\n",
      "2507/2507 [==============================] - 2s 881us/step - loss: 0.0948 - accuracy: 0.9386\n",
      "Epoch 43/100\n",
      "2507/2507 [==============================] - 2s 861us/step - loss: 0.0947 - accuracy: 0.9422\n",
      "Epoch 44/100\n",
      "2507/2507 [==============================] - 2s 865us/step - loss: 0.0943 - accuracy: 0.9426\n",
      "Epoch 45/100\n",
      "2507/2507 [==============================] - 2s 874us/step - loss: 0.0947 - accuracy: 0.9390\n",
      "Epoch 46/100\n",
      "2507/2507 [==============================] - 2s 875us/step - loss: 0.0947 - accuracy: 0.9362\n",
      "Epoch 47/100\n",
      "2507/2507 [==============================] - 2s 870us/step - loss: 0.0949 - accuracy: 0.9374\n",
      "Epoch 48/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.0986 - accuracy: 0.9338\n",
      "Epoch 49/100\n",
      "2507/2507 [==============================] - 2s 867us/step - loss: 0.0950 - accuracy: 0.9414\n",
      "Epoch 50/100\n",
      "2507/2507 [==============================] - 2s 850us/step - loss: 0.0947 - accuracy: 0.9358\n",
      "Epoch 51/100\n",
      "2507/2507 [==============================] - 2s 848us/step - loss: 0.1017 - accuracy: 0.9358\n",
      "Epoch 52/100\n",
      "2507/2507 [==============================] - 2s 854us/step - loss: 0.0967 - accuracy: 0.9350\n",
      "Epoch 53/100\n",
      "2507/2507 [==============================] - 2s 864us/step - loss: 0.0951 - accuracy: 0.9370\n",
      "Epoch 54/100\n",
      "2507/2507 [==============================] - 2s 860us/step - loss: 0.0953 - accuracy: 0.9386\n",
      "Epoch 55/100\n",
      "2507/2507 [==============================] - 2s 856us/step - loss: 0.0946 - accuracy: 0.9362\n",
      "Epoch 56/100\n",
      "2507/2507 [==============================] - 2s 853us/step - loss: 0.0944 - accuracy: 0.9374\n",
      "Epoch 57/100\n",
      "2507/2507 [==============================] - 2s 862us/step - loss: 0.0956 - accuracy: 0.9354\n",
      "Epoch 58/100\n",
      "2507/2507 [==============================] - 2s 884us/step - loss: 0.0943 - accuracy: 0.9430\n",
      "Epoch 59/100\n",
      "2507/2507 [==============================] - 2s 890us/step - loss: 0.0943 - accuracy: 0.9414\n",
      "Epoch 60/100\n",
      "2507/2507 [==============================] - 2s 889us/step - loss: 0.0964 - accuracy: 0.9342\n",
      "Epoch 61/100\n",
      "2507/2507 [==============================] - 2s 906us/step - loss: 0.0946 - accuracy: 0.9370\n",
      "Epoch 62/100\n",
      "2507/2507 [==============================] - 2s 899us/step - loss: 0.0949 - accuracy: 0.9366\n",
      "Epoch 63/100\n",
      "2507/2507 [==============================] - 2s 878us/step - loss: 0.0944 - accuracy: 0.9398\n",
      "Epoch 64/100\n",
      "2507/2507 [==============================] - 2s 904us/step - loss: 0.0951 - accuracy: 0.9370\n",
      "Epoch 65/100\n",
      "2507/2507 [==============================] - 2s 890us/step - loss: 0.0944 - accuracy: 0.9402\n",
      "Epoch 66/100\n",
      "2507/2507 [==============================] - 2s 862us/step - loss: 0.0943 - accuracy: 0.9390\n",
      "Epoch 67/100\n",
      "2507/2507 [==============================] - 2s 862us/step - loss: 0.1049 - accuracy: 0.9358\n",
      "Epoch 68/100\n",
      "2507/2507 [==============================] - 2s 952us/step - loss: 0.0949 - accuracy: 0.9350\n",
      "Epoch 69/100\n",
      "2507/2507 [==============================] - 2s 899us/step - loss: 0.0950 - accuracy: 0.9382\n",
      "Epoch 70/100\n",
      "2507/2507 [==============================] - 2s 987us/step - loss: 0.0943 - accuracy: 0.9370\n",
      "Epoch 71/100\n",
      "2507/2507 [==============================] - 2s 932us/step - loss: 0.0943 - accuracy: 0.9402\n",
      "Epoch 72/100\n",
      "2507/2507 [==============================] - 2s 880us/step - loss: 0.0947 - accuracy: 0.9398\n",
      "Epoch 73/100\n",
      "2507/2507 [==============================] - 2s 863us/step - loss: 0.0946 - accuracy: 0.9370\n",
      "Epoch 74/100\n",
      "2507/2507 [==============================] - 2s 867us/step - loss: 0.0940 - accuracy: 0.9418\n",
      "Epoch 75/100\n",
      "2507/2507 [==============================] - 2s 862us/step - loss: 0.0954 - accuracy: 0.9366\n",
      "Epoch 76/100\n",
      "2507/2507 [==============================] - 2s 864us/step - loss: 0.0944 - accuracy: 0.9382\n",
      "Epoch 77/100\n",
      "2507/2507 [==============================] - 2s 847us/step - loss: 0.0948 - accuracy: 0.9398\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 2s 831us/step - loss: 0.0944 - accuracy: 0.9334\n",
      "Epoch 79/100\n",
      "2507/2507 [==============================] - 2s 815us/step - loss: 0.0946 - accuracy: 0.9394\n",
      "Epoch 80/100\n",
      "2507/2507 [==============================] - 2s 829us/step - loss: 0.0940 - accuracy: 0.9358\n",
      "Epoch 81/100\n",
      "2507/2507 [==============================] - 2s 827us/step - loss: 0.0941 - accuracy: 0.9374\n",
      "Epoch 82/100\n",
      "2507/2507 [==============================] - 2s 825us/step - loss: 0.0945 - accuracy: 0.9350\n",
      "Epoch 83/100\n",
      "2507/2507 [==============================] - 2s 812us/step - loss: 0.0948 - accuracy: 0.9366\n",
      "Epoch 84/100\n",
      "2507/2507 [==============================] - 2s 819us/step - loss: 0.0948 - accuracy: 0.9374\n",
      "Epoch 85/100\n",
      "2507/2507 [==============================] - 2s 825us/step - loss: 0.0976 - accuracy: 0.9350\n",
      "Epoch 86/100\n",
      "2507/2507 [==============================] - 2s 829us/step - loss: 0.0949 - accuracy: 0.9342\n",
      "Epoch 87/100\n",
      "2507/2507 [==============================] - 2s 815us/step - loss: 0.0945 - accuracy: 0.9346\n",
      "Epoch 88/100\n",
      "2507/2507 [==============================] - 2s 806us/step - loss: 0.0949 - accuracy: 0.9358\n",
      "Epoch 89/100\n",
      "2507/2507 [==============================] - 2s 802us/step - loss: 0.0946 - accuracy: 0.9410\n",
      "Epoch 90/100\n",
      "2507/2507 [==============================] - 2s 853us/step - loss: 0.0943 - accuracy: 0.9346\n",
      "Epoch 91/100\n",
      "2507/2507 [==============================] - 2s 843us/step - loss: 0.0942 - accuracy: 0.9374\n",
      "Epoch 92/100\n",
      "2507/2507 [==============================] - 2s 851us/step - loss: 0.0980 - accuracy: 0.9342\n",
      "Epoch 93/100\n",
      "2507/2507 [==============================] - 2s 853us/step - loss: 0.0980 - accuracy: 0.9354\n",
      "Epoch 94/100\n",
      "2507/2507 [==============================] - 2s 837us/step - loss: 0.1303 - accuracy: 0.9370\n",
      "Epoch 95/100\n",
      "2507/2507 [==============================] - 2s 844us/step - loss: 0.1567 - accuracy: 0.9326\n",
      "Epoch 96/100\n",
      "2507/2507 [==============================] - 2s 840us/step - loss: 0.1318 - accuracy: 0.9350\n",
      "Epoch 97/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.1207 - accuracy: 0.9374\n",
      "Epoch 98/100\n",
      "2507/2507 [==============================] - 2s 848us/step - loss: 0.1108 - accuracy: 0.9366\n",
      "Epoch 99/100\n",
      "2507/2507 [==============================] - 2s 846us/step - loss: 0.0964 - accuracy: 0.9394\n",
      "Epoch 100/100\n",
      "2507/2507 [==============================] - 2s 891us/step - loss: 0.1006 - accuracy: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f20f06e8278>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#fit sentiment classifier\n",
    "sentiment_model.fit(reviews_tokenized, dummy_new, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_reviews = [\n",
    "    \"The food was lousy - too sweet or too salty and the portions tiny\",\n",
    "    \"After all that, they complained to me about the small tip\",\n",
    "    \"I have eaten at Saul, many times, the food is always consistently, outrageously good\",\n",
    "    \"The duck confit is always amazing and the foie gras terrine with figs was out of this world\",\n",
    "    \"Avoid this place!\"\n",
    "]\n",
    "                             \n",
    "# Sentiment preprocessing\n",
    "test_sentiment_terms = []\n",
    "for review in nlp.pipe(test_reviews):\n",
    "        if review.is_parsed:\n",
    "            test_sentiment_terms.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n",
    "        else:\n",
    "            test_sentiment_terms.append('') \n",
    "test_sentiment_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_sentiment_terms))\n",
    "\n",
    "# Models output\n",
    "test_sentiment = label_encoder.inverse_transform(sentiment_model.predict_classes(test_sentiment_terms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was lousy - too sweet or too salty and the portions tiny is expressing a negative\n",
      "Review: After all that, they complained to me about the small tip is expressing a positive\n",
      "Review: I have eaten at Saul, many times, the food is always consistently, outrageously good is expressing a positive\n",
      "Review: The duck confit is always amazing and the foie gras terrine with figs was out of this world is expressing a positive\n",
      "Review: Avoid this place! is expressing a negative\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(test_reviews,test_sentiment):\n",
    "    print(\"Review:\"+\" \"+str(i)+\" \"+\"is expressing a\"+ \" \" +str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
